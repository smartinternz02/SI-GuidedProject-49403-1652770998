{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXLVshdMDce7"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "import tensorflow\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCeVYrYqD0i3"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cejhbBLqECCD",
        "outputId": "31fc482a-a08d-4373-a96d-db7d25bd965e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1284 images belonging to 2 classes.\n",
            "Found 320 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "x_train = train_datagen.flow_from_directory(r\"/content/drive/MyDrive/SI-GuidedProject-49403-1652770998/dataset/train\",target_size=(128,128),batch_size= 4, class_mode='binary')\n",
        "x_test = test_datagen.flow_from_directory(r\"/content/drive/MyDrive/SI-GuidedProject-49403-1652770998/dataset/test\",target_size=(128,128),batch_size= 4, class_mode='binary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5kIX_wbEE4B"
      },
      "outputs": [],
      "source": [
        "model =Sequential()\n",
        "\n",
        "# Convolutional layer and maxpool layer 1\n",
        "model.add(Conv2D(512,(3,3),activation='relu',input_shape=(128,128,3)))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "\n",
        "# Convolutional layer and maxpool layer 2\n",
        "model.add(Conv2D(512,(3,3),activation='relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "\n",
        "# Convolutional layer and maxpool layer 3\n",
        "model.add(Conv2D(256,(3,3),activation='relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "\n",
        "# Convolutional layer and maxpool layer 4\n",
        "model.add(Conv2D(128,(3,3),activation='relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "\n",
        "# This layer flattens the resulting image array to 1D array\n",
        "model.add(Flatten())\n",
        "\n",
        "# Hidden layer with 512 neurons and Rectified Linear Unit activation function \n",
        "model.add(Dense(512,activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "# Output layer with single neuron which gives 0 for Cat or 1 for Dog \n",
        "#Here we use sigmoid activation function which makes our model output to lie between 0 and 1\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jnKHEznlrLP",
        "outputId": "39ac251c-ee79-4a69-9d66-d0eafe410a38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_24\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_71 (Conv2D)          (None, 126, 126, 512)     14336     \n",
            "                                                                 \n",
            " max_pooling2d_71 (MaxPoolin  (None, 63, 63, 512)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_72 (Conv2D)          (None, 61, 61, 512)       2359808   \n",
            "                                                                 \n",
            " max_pooling2d_72 (MaxPoolin  (None, 30, 30, 512)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_73 (Conv2D)          (None, 28, 28, 256)       1179904   \n",
            "                                                                 \n",
            " max_pooling2d_73 (MaxPoolin  (None, 14, 14, 256)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_74 (Conv2D)          (None, 12, 12, 128)       295040    \n",
            "                                                                 \n",
            " max_pooling2d_74 (MaxPoolin  (None, 6, 6, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_19 (Flatten)        (None, 4608)              0         \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 512)               2359808   \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,209,409\n",
            "Trainable params: 6,209,409\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNmHw--ZEWFn",
        "outputId": "0a29521c-fc62-4d55-84ef-9e08b1ab6fcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "321/321 [==============================] - 17s 52ms/step - loss: 0.6940 - accuracy: 0.5514 - val_loss: 0.7119 - val_accuracy: 0.5000\n",
            "Epoch 2/40\n",
            "321/321 [==============================] - 17s 52ms/step - loss: 0.6930 - accuracy: 0.5327 - val_loss: 0.6920 - val_accuracy: 0.5000\n",
            "Epoch 3/40\n",
            "321/321 [==============================] - 17s 52ms/step - loss: 0.6768 - accuracy: 0.5382 - val_loss: 0.6528 - val_accuracy: 0.4938\n",
            "Epoch 4/40\n",
            "321/321 [==============================] - 17s 51ms/step - loss: 0.6337 - accuracy: 0.5701 - val_loss: 0.6113 - val_accuracy: 0.6875\n",
            "Epoch 5/40\n",
            "321/321 [==============================] - 16s 51ms/step - loss: 0.6157 - accuracy: 0.6199 - val_loss: 0.6926 - val_accuracy: 0.5188\n",
            "Epoch 6/40\n",
            "321/321 [==============================] - 16s 51ms/step - loss: 0.5836 - accuracy: 0.6651 - val_loss: 0.5302 - val_accuracy: 0.7250\n",
            "Epoch 7/40\n",
            "321/321 [==============================] - 17s 52ms/step - loss: 0.5992 - accuracy: 0.6830 - val_loss: 0.5385 - val_accuracy: 0.7063\n",
            "Epoch 8/40\n",
            "321/321 [==============================] - 17s 51ms/step - loss: 0.5692 - accuracy: 0.7009 - val_loss: 0.5258 - val_accuracy: 0.7344\n",
            "Epoch 9/40\n",
            "321/321 [==============================] - 17s 51ms/step - loss: 0.5455 - accuracy: 0.7165 - val_loss: 0.5041 - val_accuracy: 0.7406\n",
            "Epoch 10/40\n",
            "321/321 [==============================] - 16s 51ms/step - loss: 0.5240 - accuracy: 0.7227 - val_loss: 0.5723 - val_accuracy: 0.7031\n",
            "Epoch 11/40\n",
            "321/321 [==============================] - 16s 51ms/step - loss: 0.5067 - accuracy: 0.7329 - val_loss: 0.4951 - val_accuracy: 0.7625\n",
            "Epoch 12/40\n",
            "321/321 [==============================] - 17s 51ms/step - loss: 0.4961 - accuracy: 0.7430 - val_loss: 0.5431 - val_accuracy: 0.7406\n",
            "Epoch 13/40\n",
            "321/321 [==============================] - 17s 51ms/step - loss: 0.5027 - accuracy: 0.7492 - val_loss: 0.5109 - val_accuracy: 0.7563\n",
            "Epoch 14/40\n",
            "321/321 [==============================] - 16s 51ms/step - loss: 0.4822 - accuracy: 0.7601 - val_loss: 0.4931 - val_accuracy: 0.7656\n",
            "Epoch 15/40\n",
            "321/321 [==============================] - 17s 51ms/step - loss: 0.4729 - accuracy: 0.7734 - val_loss: 0.5276 - val_accuracy: 0.7531\n",
            "Epoch 16/40\n",
            "321/321 [==============================] - 17s 51ms/step - loss: 0.4705 - accuracy: 0.7695 - val_loss: 0.4708 - val_accuracy: 0.7906\n",
            "Epoch 17/40\n",
            "321/321 [==============================] - 16s 51ms/step - loss: 0.4593 - accuracy: 0.7835 - val_loss: 0.5019 - val_accuracy: 0.7781\n",
            "Epoch 18/40\n",
            "321/321 [==============================] - 16s 51ms/step - loss: 0.4657 - accuracy: 0.7765 - val_loss: 0.4653 - val_accuracy: 0.7937\n",
            "Epoch 19/40\n",
            "321/321 [==============================] - 16s 51ms/step - loss: 0.4518 - accuracy: 0.7952 - val_loss: 0.4703 - val_accuracy: 0.7812\n",
            "Epoch 20/40\n",
            "321/321 [==============================] - 17s 51ms/step - loss: 0.4704 - accuracy: 0.7765 - val_loss: 0.4849 - val_accuracy: 0.7844\n",
            "Epoch 21/40\n",
            "321/321 [==============================] - 17s 51ms/step - loss: 0.4523 - accuracy: 0.7866 - val_loss: 0.4600 - val_accuracy: 0.8000\n",
            "Epoch 22/40\n",
            "321/321 [==============================] - 17s 51ms/step - loss: 0.4412 - accuracy: 0.7897 - val_loss: 0.5033 - val_accuracy: 0.7812\n",
            "Epoch 23/40\n",
            "321/321 [==============================] - 16s 51ms/step - loss: 0.4544 - accuracy: 0.7858 - val_loss: 0.4669 - val_accuracy: 0.8094\n",
            "Epoch 24/40\n",
            "321/321 [==============================] - 16s 51ms/step - loss: 0.4359 - accuracy: 0.8006 - val_loss: 0.4635 - val_accuracy: 0.8062\n",
            "Epoch 25/40\n",
            "321/321 [==============================] - 16s 51ms/step - loss: 0.4448 - accuracy: 0.7975 - val_loss: 0.4391 - val_accuracy: 0.8094\n",
            "Epoch 26/40\n",
            "321/321 [==============================] - 16s 51ms/step - loss: 0.4277 - accuracy: 0.8061 - val_loss: 0.4863 - val_accuracy: 0.7875\n",
            "Epoch 27/40\n",
            "321/321 [==============================] - 17s 51ms/step - loss: 0.4243 - accuracy: 0.8037 - val_loss: 0.4359 - val_accuracy: 0.8188\n",
            "Epoch 28/40\n",
            "321/321 [==============================] - 17s 51ms/step - loss: 0.4297 - accuracy: 0.7998 - val_loss: 0.4525 - val_accuracy: 0.8062\n",
            "Epoch 29/40\n",
            "321/321 [==============================] - 17s 51ms/step - loss: 0.4228 - accuracy: 0.8115 - val_loss: 0.4168 - val_accuracy: 0.8313\n",
            "Epoch 30/40\n",
            "321/321 [==============================] - 17s 51ms/step - loss: 0.4226 - accuracy: 0.8069 - val_loss: 0.4278 - val_accuracy: 0.8188\n",
            "Epoch 31/40\n",
            "321/321 [==============================] - 16s 51ms/step - loss: 0.4206 - accuracy: 0.8037 - val_loss: 0.4461 - val_accuracy: 0.8094\n",
            "Epoch 32/40\n",
            "321/321 [==============================] - 17s 51ms/step - loss: 0.4170 - accuracy: 0.8131 - val_loss: 0.4356 - val_accuracy: 0.8062\n",
            "Epoch 33/40\n",
            "321/321 [==============================] - 17s 51ms/step - loss: 0.4055 - accuracy: 0.8107 - val_loss: 0.5041 - val_accuracy: 0.7937\n",
            "Epoch 34/40\n",
            "321/321 [==============================] - 17s 52ms/step - loss: 0.4146 - accuracy: 0.7960 - val_loss: 0.4345 - val_accuracy: 0.8250\n",
            "Epoch 35/40\n",
            "321/321 [==============================] - 16s 51ms/step - loss: 0.4314 - accuracy: 0.8014 - val_loss: 0.5056 - val_accuracy: 0.7969\n",
            "Epoch 36/40\n",
            "321/321 [==============================] - 17s 51ms/step - loss: 0.4369 - accuracy: 0.7983 - val_loss: 0.4390 - val_accuracy: 0.7937\n",
            "Epoch 37/40\n",
            "321/321 [==============================] - 17s 51ms/step - loss: 0.4354 - accuracy: 0.7998 - val_loss: 0.4166 - val_accuracy: 0.8000\n",
            "Epoch 38/40\n",
            "321/321 [==============================] - 17s 51ms/step - loss: 0.4205 - accuracy: 0.7998 - val_loss: 0.4583 - val_accuracy: 0.8094\n",
            "Epoch 39/40\n",
            "321/321 [==============================] - 17s 52ms/step - loss: 0.4134 - accuracy: 0.8100 - val_loss: 0.3954 - val_accuracy: 0.8219\n",
            "Epoch 40/40\n",
            "321/321 [==============================] - 17s 52ms/step - loss: 0.4036 - accuracy: 0.8022 - val_loss: 0.4170 - val_accuracy: 0.8188\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fccf92dd1d0>"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "model.fit(x_train,  epochs=40, validation_data=x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxocz4qTGaz8"
      },
      "outputs": [],
      "source": [
        "model.save(\"/content/drive/MyDrive/SI-GuidedProject-49403-1652770998/iceberg.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TVYrgh7a-6yU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TrainNew.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}